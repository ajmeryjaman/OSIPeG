% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/osipeg_confint.R
\name{osipeg_confint}
\alias{osipeg_confint}
\title{Confidence intervals for one-step improved penalized G-estimator (OSIPeG)}
\usage{
osipeg_confint(
  data,
  wc.str,
  id.var,
  treat.var,
  response.var,
  tf.model,
  estimate,
  alpha.hat,
  sigma2.hat,
  lambda,
  test.size,
  tune.par.seq,
  continuous.covs
)
}
\arguments{
\item{data}{A data frame containing the variables in longitudinal format. In the data, the
outcome should be continuous and the treatment/exposure should be binary.}

\item{wc.str}{A character string specifying the working correlation structure. The
following are currently allowed: "independence", "exchangeable", "ar1", and "unstructured".}

\item{id.var}{The column name in data that corresponds to the variable id (unique identifier).}

\item{treat.var}{The column name in data that corresponds to the treatment/exposure variable.}

\item{response.var}{The column name in data that corresponds to the response variable.}

\item{tf.model}{A single formula object specifying the covariates of a (linear)
treatment-free model.}

\item{estimate}{The vector of blip parameter estimates obtained using penalized G-estimation.}

\item{alpha.hat}{The estimated correlation parameter(s) alpha(s) if the provided structure is either
"exchangeable", "ar1, or "unstructured". For unstructured, the elements of alpha.hat correspond
to the upper triangular portion of working correlation matrix having dimension equal to
the largest cluster size.}

\item{sigma2.hat}{The estimated variance parameter sigma^2.}

\item{lambda}{The optimal tuning parameter returned by penalized G-estimation.}

\item{test.size}{The significance level. For a 95\% confidence interval test.size should be 0.05.}

\item{tune.par.seq}{A sequence of values (in decreasing order) for the tuning parameter to execute
the dantzig selector. This is used to find the optimal weight vector.}

\item{continuous.covs}{A logical vector of TRUE/FALSE values identifying the potential
effect modifiers that are continuous.}
}
\value{
A list containing the following:
\item{CI.one.step.full}{A matrix showing confidence interval estimates for the selected blip
coefficients, calculated using the full weight vector.}
\item{CI.one.step.LASSO}{A matrix showing confidence interval estimates for the selected blip
coefficients, using the sparse weight vector obtained via LASSO.}
\item{CI.one.step.dantzig}{A matrix showing confidence interval estimates for the selected blip
coefficients, using the sparse weight vector obtained via the Datzig selector.}
}
\description{
This function implements a decorrelated score approach to provide confidence intervals
for the blip coefficients selected by penalized G-estimation in the context of a structural nested mean
model (SNMM) for repeated outcomes.
}
\examples{
library(mvtnorm)

expit <- function(x) exp(x)/(1+exp(x))

## data.gen is a function that generates a longitudinal data set for a specific correlation
## structure. Available structures in this function are: independence, exchangeable and AR1.

## Arguments(data.gen):
#     n = Number of subjects
#     ni = A vector containing number of time points for each subject
#     sigma2.e = Error variance
#     alpha = Correlation parameter
#     corstr = The correlation structure among the repeated outcomes
#     autocorr.coef = The autocorrelation coefficient for inducing correlation among the
#     continuous confounders and the noise covariates

data.gen <- function(n, ni, sigma2.e, alpha, corstr, autocorr.coef){
 ncovs  <-  2+4+45 # 2+4=6 confounders and 45 noise covariates
  beta <- c(0, 1, -1.1, 1.2, 0.75, -0.9, 1.2) # treatment model parameters
  delta <- c(1, 1, 1.2, 1.2, -0.9, 0.8, -1,
             rep(1, 20), rep(0, ncovs-6-20),
             -0.8, 1, 1.2, -1.5) # treatment-free model parameters
  psi <- c(1, 1, -1, -0.9, 0.8, 1, 0, rep(0, 20), rep(0, ncovs-6-20)) # blip parameters

  # generating two continuous baseline covariates
  l1 <- rnorm(n, 0, 1)
  l2 <- rnorm(n, 0, 1)

  # V is the covariance matrix of the time-varying confounders (l3,..,l6) and
  # noise covariates (x1,...)
  V <- toeplitz(autocorr.coef^(0:(ncovs-2-1)))

  lx <- a <- y <- vector(mode="list", length=n)
  lx.mat <- NULL
  for(i in 1:n){
    a[[i]] <- y[[i]] <- rep(NA, ni[i])
    lx[[i]] <- matrix(NA, ni[i], ncovs)
    lx[[i]][,1] <- rep(l1[i], ni[i])
    lx[[i]][,2] <- rep(l2[i], ni[i])

    corr.mat <- switch(corstr,
                       "exchangeable" = toeplitz(c(1, rep(alpha, ni[i]-1))),
                       "ar1" = toeplitz(alpha^(0:(ni[i]-1))),
                       "independence" = diag(ni[i])
    )
    cov.mat <- diag(sqrt(sigma2.e), ni[i]) \%*\% corr.mat \%*\% diag(sqrt(sigma2.e), ni[i])
    e <- rmvnorm(1, sigma = cov.mat)

    # j=1
    mu.lx <- c(NA, NA, # for l1 and l2
               rep(0, 4), rep(0, ncovs-6)) #rep(0.3*lx[[i]][1, 1]+0.3*lx[[i]][1, 2],4)
    lx[[i]][1,3:ncovs] <- rmvnorm(1, mean=mu.lx[3:ncovs], sigma = V)
    a[[i]][1] <- rbinom(1, 1, expit(sum(c(1,lx[[i]][1,1:6])*beta)))  ## no correlation
    tf.mean <- sum(c(1, lx[[i]][1,1:ncovs],
                     lx[[i]][1,1]*lx[[i]][1,5], lx[[i]][1,3]*lx[[i]][1,4], sin(lx[[i]][1,3]-lx[[i]][1,4]),
                     cos(2*lx[[i]][1,5])) * delta)
    blip <- sum(c(a[[i]][1], a[[i]][1]*c(lx[[i]][1,1:ncovs])) * psi)
    y[[i]][1] <- (tf.mean + blip) + e[1]


    # j=2:ni
    for(j in 2:ni[i]){
      mu.lx <- c(NA, NA, # for l1 and l2
                 0.3*lx[[i]][j-1, 3:6] + 0.3*a[[i]][j-1], 0.5*lx[[i]][j-1,7:ncovs])
      lx[[i]][j,3:ncovs] <- rmvnorm(1, mean=mu.lx[3:ncovs], sigma = V)
      a[[i]][j] <- rbinom(1, 1, expit(sum(c(1,lx[[i]][j,1:6])*beta)))  ## no correlation
      tf.mean <- sum(c(1, lx[[i]][j,1:ncovs],
                       lx[[i]][j,1]*lx[[i]][j,5], lx[[i]][j,3]*lx[[i]][j,4], sin(lx[[i]][j,3]-lx[[i]][j,4]),
                       cos(2*lx[[i]][j,5])) * delta)
      blip <- sum(c(a[[i]][j], a[[i]][j]*c(lx[[i]][j,1:ncovs])) * psi)
      y[[i]][j] <- (tf.mean + blip) + e[j]
    }
    lx.mat <- rbind(lx.mat, lx[[i]])
  }

  colnames(lx.mat) <- c(paste("l", 1:6, sep=""), paste("x", 1:(ncovs-6), sep=""))
  data <- data.frame(id=rep(1:n, times=ni), a=unlist(a), lx.mat, y=round(unlist(y),3))
  return(data)
}

data.s <- data.gen(n = 500, ni = rep(6, 500), sigma2.e = 1, alpha = 0.8,
                   corstr = "exchangeable", autocorr.coef = 0.25)

ncovs  <-  2+4+45
# treatment-free model is misspecified
tf.model <- as.formula(paste("~",paste(c(paste("l",1:6,sep=""), paste("x",c(1:9,11:(ncovs-6)),sep="")),
                                       collapse = "+"), collapse=""))
treat.model <- ~l1+l2+l3+l4+l5+l6

lam_max <- 1
lam_min <- 0.01*lam_max
lambda.seq <- sort(seq(lam_min,lam_max,(lam_max-lam_min)/99), decreasing=TRUE)

# library(devtools) # if already installed, otherwise need to install it first
# install_github("ajmeryjaman/penalizedG") # run this command if this package is not already installed
library(penalizedG)

# Run penalized G-estimation for a sequence of tuning parameters (lambda)
out <- penalizedG(data = data.s, wc.str = "exchangeable", id.var="id", response.var="y",
                   treat.var="a", tf.model=tf.model, treat.model = treat.model,
                   lambda.seq = lambda.seq, maxitr = 100, penalty = "SCAD")
out$selected.EMs

data <- out$data # have an additional column containing the propensity scores

# confidence interval for OSIPeG (using the decorrelated score approach)
library(flare)
CI.osipeg <- osipeg_confint(data = data, wc.str = "exchangeable", id.var = "id", response.var = "y",
                            treat.var = "a", tf.model = tf.model, estimate = out$estimate,
                            alpha.hat = out$alpha.hat, sigma2.hat = out$sigma2.hat,
                            lambda = out$lambda.optimal, test.size = 0.05,
                           tune.par.seq = sort(seq(0,0.2,(0.2-0)/100), decreasing = TRUE),
                           continuous.covs = rep(TRUE, length(all.vars(tf.model))))
CI.osipeg$CI.one.step.full
CI.osipeg$CI.one.step.LASSO
CI.osipeg$CI.one.step.dantzig

# Naive CI based on sandwich variance
p <- length(model.matrix(tf.model, data=data)[1,])
psi.hat <- out$estimate[1:p]
effect.modification <- psi.hat[2:p]
M <- c(TRUE, abs(effect.modification) > 0.001)

CI.naive <- cbind(psi.hat[M] - qnorm(0.975)*sqrt(diag(out$asymp.var.psi[M,M])),
                  psi.hat[M] + qnorm(0.975)*sqrt(diag(out$asymp.var.psi[M,M])))
CI.naive
}
